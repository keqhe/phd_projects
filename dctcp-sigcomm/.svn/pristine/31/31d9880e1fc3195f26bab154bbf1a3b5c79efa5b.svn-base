\section{Related Work}
\label{related}
In this section we discuss different classes of related work.
~\eric{talk about using RWND? Freeze TCP and incast tcp?}

\tightparagraph{Congestion control for DCNs}
DCTCP~\cite{alizadeh2011data} is a seminal TCP variant for datacenter networks.
TCP-Bolt~\cite{stephens2014practical} is a variant of DCTCP for PFC-enabled lossless Ethernet (DCB).
%DCQCN~\cite{zhu2015congestion} is a rate-based congestion control scheme implemented in NICs
%for QCN-based~\cite{qcn} RDMA deployments.
DCQCN~\cite{zhu2015congestion} is a rate-based congestion control scheme (built on DCTCP and QCN) to
support RDMA deployments in PFC-enabled lossless networks.
TIMELY~\cite{mittal2015timely} and DX~\cite{lee2015accurate} 
use accurate network latency as the signal to perform congestion control.
Judd~\cite{judd2015nsdi} proposed simple yet practical fixes to enable DCTCP in production networks.
TCP ex Machina~\cite{winstein2013tcp} uses computer-generated congestion control rules.
PERC~\cite{jose2015high} proposes proactive congestion control to improve convergence.
ICTCP~\cite{wu2010ictcp}'s receiver monitors incoming TCP flows and 
modifies~\rwnd{} to mitigate the impact of incast. In~\acdc{},~\rwnd{}
is modified at the sender to enforce the behavior of a DCTCP stack.
There have been discussions~\cite{mogul2003tcp} and efforts~\cite{dell-toe,chelsio-toe} to 
implement TCP Offload Engine (TOE) in the NIC. 
But TOE has not been widely deployed and adopted for reasons as noted in~\cite{mogul2003tcp,linux-toe}.

\tightparagraph{Bandwidth allocation} Many bandwith allocation schemes have been proposed.
Gatekeeper~\cite{rodrigues2011gatekeeper} and EyeQ~\cite{jeyakumar2013eyeq} abstract the network as a single
switch and provide bandwidth guarentees by managing each server's access link.
Oktopus~\cite{Ballani2011oktopus} provides fixed performance guarentees within virtual clusters.
SecondNet~\cite{Guo2010Secondnet} enables virtual datacenters with static bandwidth guarentees.
Proteus~\cite{Xie2012Proteus} allocates bandwidth for applications with dynamic demands.
Seawall~\cite{shieh2011sharing} provides bandwidth proportional to a defined weight by
forcing traffic through congestion-based edge-to-edge tunnels. 
NetShare~\cite{Lam2012NetShare} utilizes hierarchical weighted max-min fair sharing to tune relative bandwidth allocation for services.
FairCloud~\cite{Popa2012Faircloud} identifies trade-offs in minimum
guarentees, proportionality and high utilization, and designs schemes over this space.
Silo~\cite{jang2015silo} provides guarenteed bandwidth, delay and burst allowances through a novel VM placement and admission 
algorithm, coupled with a fine-grained packet pacer. 
~\eric{DLR work mentioned in Seawall?}
~\acdc{} is largely complimentary to these schemes because it is a transport-level solution.

\tightparagraph{Rate limiters} 
SENIC~\cite{niranjan2013fastrak} 
identifies the limitations of NIC hardware rate limiters (\ie{}, not scalable) and 
software rate limiters (\ie{}, high CPU overhead) and uses the CPU to enqueue packets 
in host memory and NIC hardware to perform packet scheduling. Silo~\cite{jang2015silo}'s pacer injects void packets into 
original packet sequence to achieve pacing. FasTrack~\cite{niranjan2013fastrak} offloads
functionality from the server into the switch for certain flows.

\tightparagraph{Low latency DCNs}
HULL~\cite{alizadeh2012less} uses phantom queues to leave bandwidth headroom to support low latency.
pFabric~\cite{alizadeh2013pfabric} is a clean-slate
design which utilizes priority and minimal switch buffering to achieve low latency.
Fastpass~\cite{perry2014fastpass} uses a centralized arbiter to
perform per-packet level scheduling.
QJUMP~\cite{qjump} uses priority queueing and rate limiting to
bound latency. Traffic engineering~\cite{al2010hedera,rasley2014planck} and 
load balancing~\cite{alizadeh2014conga,he2015presto,ghorbani2015micro} can also
reduce latency.~\eric{add one more TE scheme?}

